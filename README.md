(~2 weeks complete attention.cu)\
relevant links/readings:\
[https://gordicaleksa.medium.com/eli5-flash-attention-5c44017022ad]\
[https://arxiv.org/pdf/2205.14135]\
basically a cuda version of this [stanford project](https://github.com/stanford-cs149/cs149gpt)

# gpt2-flash-attention
