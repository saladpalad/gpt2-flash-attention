# gpt2-flash-attention
a cuda port of this [stanford assignment](https://github.com/stanford-cs149/cs149gpt)
